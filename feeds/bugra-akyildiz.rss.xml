<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Bugra Akyildiz - Bugra Akyildiz</title><link>http://bugra.github.io/</link><description></description><lastBuildDate>Sun, 19 Feb 2017 00:00:00 +0000</lastBuildDate><item><title>Similarity in the Wild</title><link>http://bugra.github.io/work/notes/2017-02-19/similarity-in-the-wild/</link><description>&lt;p&gt;&lt;img alt="Similarity Matrix" src="/images/work/notes/2017/2/19/similarity-matrix.png"&gt;&lt;/p&gt;
&lt;p&gt;This post has been published in Axial's blog post where I used to work in search engine and recommendations. However, the original post has been removed and now I am republishing as I wrote the original post.&lt;/p&gt;
&lt;p&gt;Finding similarity across observations is one of the most common tasks/projects something …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sun, 19 Feb 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2017-02-19:/work/notes/2017-02-19/similarity-in-the-wild/</guid></item><item><title>Facts and Fallacies of Software Engineering - Book Review</title><link>http://bugra.github.io/work/notes/2017-02-11/facts-and-fallacies-of-software-engineering-book-review/</link><description>&lt;p&gt;I read &lt;a href="https://jet.com/product/Facts-and-Fallacies-of-Software-Engineering/2c6ef894a57847c89d0148f31074df16"&gt;Facts and Fallacies of Software Engineering&lt;/a&gt; and I quite enjoyed it. I enjoyed so much that I wanted a review and wanted to write down the quotes that I took.&lt;/p&gt;
&lt;p&gt;The author is very knowledgeable and he knows his stuff, at least you can get the confidence that …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 11 Feb 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2017-02-11:/work/notes/2017-02-11/facts-and-fallacies-of-software-engineering-book-review/</guid></item><item><title>Similarity via Jaccard Index</title><link>http://bugra.github.io/work/notes/2017-02-07/similarity-via-jaccard-index/</link><description>&lt;p&gt;&lt;img alt="Jaccard Index" src="/images/work/notes/2017/2/7/industry-similarity-for-jaccard-index.png"&gt;&lt;/p&gt;
&lt;p&gt;At Axial, we had a taxonomy tree for industries and wanted to know if one particular industry is more similar to another industry. The similarity of some of the industries are straightforward if they share a parent, but this similarity is not quantitative and does not produce a metric on …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Tue, 07 Feb 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2017-02-07:/work/notes/2017-02-07/similarity-via-jaccard-index/</guid></item><item><title>Topic Modeling for Keyword Extraction</title><link>http://bugra.github.io/work/notes/2017-02-05/topic-modeling-for-keyword-extraction/</link><description>&lt;p&gt;&lt;img alt="LDA Illustration" src="/images/work/notes/2017/2/5/blei_lda_illustration.png"&gt;&lt;/p&gt;
&lt;p&gt;This post was originally published at Axial’s blog, but the blog’s domain has been expired so I wanted to revive it as I wrote it originally. &lt;/p&gt;
&lt;p&gt;I added couple of sections to the blog post since then.&lt;/p&gt;
&lt;h4&gt;Taxonomy&lt;/h4&gt;
&lt;p&gt;Who is not frustrated on taxonomy more? Is it the …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sun, 05 Feb 2017 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2017-02-05:/work/notes/2017-02-05/topic-modeling-for-keyword-extraction/</guid></item><item><title>DynamoDB Learnings</title><link>http://bugra.github.io/work/notes/2016-10-23/dynamodb-learnings/</link><description>&lt;p&gt;At &lt;a href="https://hinge.co/"&gt;Hinge&lt;/a&gt;, we have been using Dynamodb in production for more than 8 months and we just relaunched &lt;a href="https://techcrunch.com/2016/10/11/the-new-hinge-focused-exclusively-on-real-relationships-now-costs-7month/"&gt;two weeks ago&lt;/a&gt; with full capacity. I want to share couple of learnings and why it made sense for us to store ratings in DynamoDB since I own the rating processing in …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sun, 23 Oct 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2016-10-23:/work/notes/2016-10-23/dynamodb-learnings/</guid></item><item><title>Basic Math on How Bloom Filter Works</title><link>http://bugra.github.io/work/notes/2016-08-27/basic-math-on-how-bloom-filter-works/</link><description>&lt;p&gt;I gave an overview on &lt;a href="https://bugra.github.io/work/notes/2016-06-05/a-gentle-introduction-to-bloom-filter/"&gt;bloom filter&lt;/a&gt; in the previous blog post. 
But if I summarize the properties of bloom filter as a data structure;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fast inserts&lt;/li&gt;
&lt;li&gt;Fast lookups&lt;/li&gt;
&lt;li&gt;No false negatives -&amp;gt; all of the items that are inserted return true for membership existence&lt;/li&gt;
&lt;li&gt;You could make the tradeoff space …&lt;/li&gt;&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 27 Aug 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2016-08-27:/work/notes/2016-08-27/basic-math-on-how-bloom-filter-works/</guid></item><item><title>A Gentle Introduction to Bloom Filter</title><link>http://bugra.github.io/work/notes/2016-06-05/a-gentle-introduction-to-bloom-filter/</link><description>&lt;h2&gt;Bloom Filter&lt;/h2&gt;
&lt;p&gt;Bloom filters are probabilistic space-efficient data structures. They are very similar to hashtables; they are used exclusively membership existence in a set. However, they have a very powerful property which allows to make trade-off between space and false-positive rate when it comes to membership existence. Since it can …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sun, 05 Jun 2016 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2016-06-05:/work/notes/2016-06-05/a-gentle-introduction-to-bloom-filter/</guid></item><item><title>Trend Estimation Methods for Time Series Signals</title><link>http://bugra.github.io/work/notes/2015-07-24/trend-estimation-methods-time-series-signals/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Trend-Estimation"&gt;Trend Estimation&lt;a class="anchor-link" href="#Trend-Estimation"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Trend estimation in a very broad sense could be defined as a family of methods to be able to detect and predict tendencies and regularities in time series signals. It is generallly highly dependent on the problem domain and application. Therefore, it begs different approaches for every other problem rather than a single solution that works across different domains.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Fri, 24 Jul 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2015-07-24:/work/notes/2015-07-24/trend-estimation-methods-time-series-signals/</guid></item><item><title>1. Introduction to Deep Learning with Lua - Gradients</title><link>http://bugra.github.io/work/notes/2015-05-17/introduction-to-deep-learning-with-lua-gradients/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Deep learning or neural networks refers to wide and deep neural network architectures, but in its core, they are nothing but circuit operations, whether it is sigmoid, multiplication or even addition operation. However, in order to learn an input and output pair, one needs to know how to compute  gradient of a function to be able to optimize the weights of the network.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sun, 17 May 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2015-05-17:/work/notes/2015-05-17/introduction-to-deep-learning-with-lua-gradients/</guid></item><item><title>Learning Lua as a Python Developer</title><link>http://bugra.github.io/work/notes/2015-05-09/learning-lua-as-a-python-developer/</link><description>&lt;p&gt;This tutorial is not the millionth tutorial that walks you through 
basic concepts of Lua language. First there are quite excellent 
&lt;a href="http://tylerneylon.com/a/learn-lua/"&gt;tutorials&lt;/a&gt;
that actually aims to do exactly that. This post would be to tell a tutorial on Lua
from a Pythonista, comparing Lua features with various Python features and …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 09 May 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2015-05-09:/work/notes/2015-05-09/learning-lua-as-a-python-developer/</guid></item><item><title>Machine Learning for Programming</title><link>http://bugra.github.io/work/notes/2015-04-26/machine-learning-for-programming/</link><description>&lt;p&gt;&lt;a href="http://norvig.com/"&gt;Peter Norvig&lt;/a&gt; presented a great overview how programming
could use more machine learning. He presented quite nice overview of what has
been done in research and what could be possible. Generally, the presentation
followed a question-answer style where he first presented the question and then
try to give answer by …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sun, 26 Apr 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2015-04-26:/work/notes/2015-04-26/machine-learning-for-programming/</guid></item><item><title>Personalization Palooza Notes</title><link>http://bugra.github.io/work/notes/2015-03-01/personalization-palooza-notes/</link><description>&lt;p&gt;&lt;a href="http://www.axial.net/"&gt;We&lt;/a&gt; attended &lt;a href="https://www.eventbrite.com/e/personalizationpalooza-tickets-15005357428"&gt;Personalization Palooza&lt;/a&gt; last week. It was a lot of fun.&lt;/p&gt;
&lt;p&gt;If you are still giggling, just ignore the name of the event for a second. Just look at the speaker list. (I know name makes hard to take the event seriously, but it was serious.) Another bummer was …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sun, 01 Mar 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2015-03-01:/work/notes/2015-03-01/personalization-palooza-notes/</guid></item><item><title>Topic Modeling for the Uninitiated</title><link>http://bugra.github.io/work/notes/2015-02-21/topic-modeling-for-the-uninitiated/</link><description>&lt;h2&gt;Motivation&lt;/h2&gt;
&lt;p&gt;As more and more data are stored digitally and people have better and improved tools for publishing, we are witnessing more and more text data has been collected and published in various mediums.(e-books, blogs, newspaper websites, magazines and mobile applications) So-called big data era not only enable people …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 21 Feb 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2015-02-21:/work/notes/2015-02-21/topic-modeling-for-the-uninitiated/</guid></item><item><title>Learning Swift Part 1</title><link>http://bugra.github.io/work/notes/2015-02-13/learning-swift-part-1/</link><description>&lt;p&gt;I have recently become interested in the very new programming language as it 
provides a sweetspot for iOS developers who are tired writing Objective-C. &lt;/p&gt;
&lt;p&gt;I spent about 5 hours looking at its syntax and functionality; I must say it feels
mostly Scala to me. There are places where syntax is …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Fri, 13 Feb 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2015-02-13:/work/notes/2015-02-13/learning-swift-part-1/</guid></item><item><title>K-Means, Sparse Coding, Dictionary Learning and All That</title><link>http://bugra.github.io/work/notes/2015-02-10/k-means-sparse-coding-dictionary-learning-and-all-that/</link><description>&lt;h2&gt;Feature Learning&lt;/h2&gt;
&lt;p&gt;Feature learning especially from images is a fundamental step in a classification
pipeline as the raw pixels create both huge feature vectors per image
and are not necessarily good to represent the image in an efficient way 
for image classification problems.&lt;/p&gt;
&lt;h2&gt;Unsupervised Feature Learning&lt;/h2&gt;
&lt;p&gt;Computer vision community came …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Tue, 10 Feb 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2015-02-10:/work/notes/2015-02-10/k-means-sparse-coding-dictionary-learning-and-all-that/</guid></item><item><title>Similarity in the Wild</title><link>http://bugra.github.io/work/notes/2015-01-31/similarity-in-the-wild/</link><description>&lt;p&gt;This post is originally posted in &lt;a href="http://axialcorps.com/2015/01/30/similarity-in-the-wild/"&gt;AxialCorps&lt;/a&gt;.
&lt;img alt="Opportunity_topic_rank_matrix" src="https://axialcorps.files.wordpress.com/2015/01/opportunity_topic_rank_matrix.png"&gt;
&lt;a href="https://axialcorps.files.wordpress.com/2015/01/opportunity_topic_rank_matrix.png"&gt;Larger Image&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Finding similarity across observations is one of the most common tasks/projects which a data scientist does. Collaborative Filtering purely depends on finding similar items(videos for Netflix, products for Amazon) for users. If you are doing a classification task with …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 31 Jan 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2015-01-31:/work/notes/2015-01-31/similarity-in-the-wild/</guid></item><item><title>Blog in Review 2014</title><link>http://bugra.github.io/work/notes/2015-01-25/blog-in-review-2014/</link><description>&lt;p&gt;This blog(I guess no matter how much I do not like this term, this website
is a blog) has been around more than 3 years by now. Last year, I made a conscious
decision that I should write more regularly and removing some of the posts that
are all …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sun, 25 Jan 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2015-01-25:/work/notes/2015-01-25/blog-in-review-2014/</guid></item><item><title>Mining a VC</title><link>http://bugra.github.io/work/notes/2015-01-17/mining-a-vc/</link><description>&lt;p&gt;Fred Wilson is one of the most popular VCs(rightly so) who is based in NY and
he has a really great &lt;a href="http://avc.com/"&gt;blog&lt;/a&gt;, where he talks about pretty much
anything with a focus on startups, venture capital and technology. No surprise here.&lt;/p&gt;
&lt;p&gt;His &lt;a href="http://avc.com/2003/09/my_first_post/"&gt;first post&lt;/a&gt; dates back to 23rd September …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 17 Jan 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2015-01-17:/work/notes/2015-01-17/mining-a-vc/</guid></item><item><title>I wish I knew these things when I learned Python</title><link>http://bugra.github.io/work/notes/2015-01-03/i-wish-i-knew-these-things-when-i-first-learned-python/</link><description>&lt;p&gt;I sometimes found myself asking myself how I cannot know simpler way of doing 
“this” thing in Python 3. When I seek solution, I of course find much more elegant,
efficient and more bug-free code parts over time. In total(not just this post), 
the total sum of “those” things …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 03 Jan 2015 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2015-01-03:/work/notes/2015-01-03/i-wish-i-knew-these-things-when-i-first-learned-python/</guid></item><item><title>Building Language Detector via Scikit-Learn</title><link>http://bugra.github.io/work/notes/2014-12-26/language-detector-via-scikit-learn/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Percentage of English language across all of the languages is decreasing and will likely to do so incoming years. All(nearly) of the tweets are written in English in 2006 whereas in 2013, only half of the tweets are written in English as Japanese, Spanish, Portuguese and other languages increase their share in the tweets. This will likely to continue if we look at the population(excluding China as they have their own networks), India, Russia, Brazil(portuguese) and Germany does not contribute with comparison to their population.(based on the assumption that the smartphones will be ubiquitous and most people who have internet access would have access to smartphones as well).&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Fri, 26 Dec 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-12-26:/work/notes/2014-12-26/language-detector-via-scikit-learn/</guid></item><item><title>Trend Estimation via Hodrick Prescott Filter</title><link>http://bugra.github.io/work/notes/2014-11-24/trend-estimation-via-hodrick-prescott-filter/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Trend-Estimation-Methods"&gt;Trend Estimation Methods&lt;a class="anchor-link" href="#Trend-Estimation-Methods"&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;With more and more sensors readily available and collection of data becomes more ubiquitous and enables machine to machine communication(a.k.a internet of things), time series signals play more and more important role in both data collection process and also naturally in the data analysis. Data aggregation from different sources and from many people make time-series analysis crucially important in these settings. 
Detecting trends and patterns in time-series signals enable people to respond these changes and take actions intelligibly. Historically, trend estimation has been useful in macroeconomics, financial time series analysis, revenue management and many more fields to reveal underlying trends from the time series signals.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Mon, 24 Nov 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-11-24:/work/notes/2014-11-24/trend-estimation-via-hodrick-prescott-filter/</guid></item><item><title>An Introduction to Supervised Learning via Scikit Learn</title><link>http://bugra.github.io/work/notes/2014-11-22/an-introduction-to-supervised-learning-scikit-learn/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Supervised-Learning"&gt;Supervised Learning&lt;a class="anchor-link" href="#Supervised-Learning"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Supervised Learning is the most commonly referred/mentioned/researched/published subfield in the machine learning. Unsurprisingly, all of the predictive algorithms fall in to this category. Its premise is quite simple, when you provide a labeled dataset to the algorithm(training set), it will predict unseen dataset's (test set) output variables, whether be it a discrete label(classification) or a continuous value(regression). The learning function(regressor or classifier) will first &lt;code&gt;fit&lt;/code&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 22 Nov 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-11-22:/work/notes/2014-11-22/an-introduction-to-supervised-learning-scikit-learn/</guid></item><item><title>An Introduction to Unsupervised Learning via Scikit Learn</title><link>http://bugra.github.io/work/notes/2014-11-16/an-introduction-to-unsupervised-learning-scikit-learn/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Unsupervised-Learning"&gt;Unsupervised Learning&lt;a class="anchor-link" href="#Unsupervised-Learning"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Unsupervised learning is the most applicable subfield on machine learning as it does not require any labels in the dataset and world is &lt;strong&gt;itself&lt;/strong&gt; is an abundance of dataset. Human beings and their actions are recorded more and more every day(through photographs in Instagram, health data through wearables, internet activity through cookies and so on). Even the part of our lives which are not digital will be recorded in near future thanks to internet of things. In such a diversified and unlabeled dataset, unsupervised learning will become more and more important in the future.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sun, 16 Nov 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-11-16:/work/notes/2014-11-16/an-introduction-to-unsupervised-learning-scikit-learn/</guid></item><item><title>Scala Basics Continued for Python Developers</title><link>http://bugra.github.io/work/notes/2014-10-20/scala-basics-continued-for-python-developers/</link><description>&lt;h2&gt;Classes&lt;/h2&gt;
&lt;h3&gt;Inheritance&lt;/h3&gt;
&lt;p&gt;In Scala, inheritance works in the same way as Java. You could extend
the parent class either overriding the methods or building on top of
parent class. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Animal&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="k"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;String&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt;&lt;span class="k"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;Int&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;family&lt;/span&gt;&lt;span class="k"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;String&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Mammalian&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="k"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;String&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt;&lt;span class="k"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;Int&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="k"&gt;extends&lt;/span&gt; &lt;span class="nc"&gt;Animal&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;age&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Mammalian&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;{}&lt;/span&gt;
&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;Insect …&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Mon, 20 Oct 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-10-20:/work/notes/2014-10-20/scala-basics-continued-for-python-developers/</guid></item><item><title>Scala Basics for Python Developers</title><link>http://bugra.github.io/work/notes/2014-10-18/scala-basics-for-python-developers/</link><description>&lt;p&gt;Python is great language, its syntax, standard library and scientific computing stack(&lt;code&gt;numpy&lt;/code&gt;, &lt;code&gt;scipy&lt;/code&gt;, &lt;code&gt;scikit-learn&lt;/code&gt;, &lt;code&gt;matplotlib&lt;/code&gt; and many others) are just great. I feel like whenever I have a problem at my hand, it will be my first to go language no matter what with the extensive library support and …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 18 Oct 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-10-18:/work/notes/2014-10-18/scala-basics-for-python-developers/</guid></item><item><title>Geometric Take on PCA</title><link>http://bugra.github.io/work/notes/2014-09-27/geometric-take-on-pca/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;If linear regression is one of the most commonly used method for regression and in general for supervised learning, Principal Component Analysis (PCA) would be the equivalent of linear regression in the unsupervised learning for mainly dimensionality reduction. 
It could be used a variety of problems, though. To name a few; data preprocessing(removing the correlations between variables), &lt;a href="http://bugra.github.io/work/notes/2013-07-27/PCA-EigenFace-And-All-That/"&gt;feature extraction&lt;/a&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 27 Sep 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-09-27:/work/notes/2014-09-27/geometric-take-on-pca/</guid></item><item><title>On Machine Learning</title><link>http://bugra.github.io/work/notes/2014-08-23/on-machine-learning/</link><description>&lt;p&gt;&lt;img alt="Sparse Colorful Filters" src="http://i.imgur.com/xmkGeNc.png" title="Colorful Sparse Filters"&gt;&lt;/p&gt;
&lt;p&gt;Recently, I wrote &lt;a href="https://www.cbinsights.com/blog/human-resources-news-classification-machine-learning"&gt;how we do classification at CB Insights&lt;/a&gt;.
The post outlines some of the things that I have been thinking about how to apply machine learning for a given problem along with the process that we adopted for the classification problem at CB Insights, but also gave me …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 23 Aug 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-08-23:/work/notes/2014-08-23/on-machine-learning/</guid></item><item><title>Name Changes Across Years in USA</title><link>http://bugra.github.io/work/notes/2014-07-31/baby-names-years-usa-social-security/</link><description>
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Thu, 31 Jul 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-07-31:/work/notes/2014-07-31/baby-names-years-usa-social-security/</guid></item><item><title>Pydata Silicon Valley 2014 Part 2</title><link>http://bugra.github.io/work/notes/2014-07-20/pydata-silicon-valley-2014-part-2/</link><description>&lt;p&gt;&lt;img alt="Pydata Silicon Valley 2014" src="http://i.imgur.com/tInmSM1.png"&gt;
The Pydata Silicon Valley videos are put into Youtube, thanks to
Facebook, Continuum and Parse.ly. Check it &lt;a href="https://www.youtube.com/user/PyDataTV"&gt;out&lt;/a&gt;.
They are pretty great. &lt;/p&gt;
&lt;p&gt;I already wrote about(kind of wrap-up) the presentations that I attended &lt;a href="http://bugra.github.io/work/notes/2014-05-12/pydata-silicon-valley-2014/"&gt;here&lt;/a&gt;.
This one will be similar to the ones that I could not attend but …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sun, 20 Jul 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-07-20:/work/notes/2014-07-20/pydata-silicon-valley-2014-part-2/</guid></item><item><title>Discrete Cosine Transform and A Case Study on Image Compression</title><link>http://bugra.github.io/work/notes/2014-07-12/discre-fourier-cosine-transform-dft-dct-image-compression/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Discrete Fourier Transform(DFT) and Discrete Cosine Transform(DCT) are commonly used algorithms to represent an arbitrary signal in terms of orhonormal basises. In DFT case, these basis functions are cosine and sinusoids(in complex form) where DCT depends on cosine signals to represent the signal. Even though DCT is more used than DFT, the approach that they use to represent signal are similar but they only differ by basis functions.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 12 Jul 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-07-12:/work/notes/2014-07-12/discre-fourier-cosine-transform-dft-dct-image-compression/</guid></item><item><title>PigPen, Hadoop, Pig, Clojure and All That</title><link>http://bugra.github.io/work/notes/2014-07-09/pigpen-hadoop-pig-clojure-cascading/</link><description>&lt;p&gt;![Big Data vs me](http://i.imgur.com/dJ5nhHd.jpg Me, When I see “big data” phrase)
My humble contribution to &lt;a href="http://bigdatapix.tumblr.com/"&gt;ridiculous images on big data&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This post is about &lt;a href="https://github.com/Netflix/PigPen"&gt;PigPen&lt;/a&gt;, a library that Netflix
open sourced in the beginning of this year. Yet, in order to introduce the library …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Wed, 09 Jul 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-07-09:/work/notes/2014-07-09/pigpen-hadoop-pig-clojure-cascading/</guid></item><item><title>Law of Large Numbers and Central Limit Theorem</title><link>http://bugra.github.io/work/notes/2014-06-26/law-of-large-numbers-central-limit-theorem/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;If one has to provide a list the important/useful theorems in probability theory, she needs to mention Law of Large Numbers and Central Limit Theorem. However, if you ask me two theorems that are most under appreciated, I would also count these two in that list as well. Most of the textbooks give probability axioms in their first chapters to provide a common ground to build probability sense, yet they will wait for quite later chapters to introduce these two very useful theorems.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Thu, 26 Jun 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-06-26:/work/notes/2014-06-26/law-of-large-numbers-central-limit-theorem/</guid></item><item><title>First, Second Derivative, Convolution and Quadratic Fitting and all that via MCMC</title><link>http://bugra.github.io/work/notes/2014-06-13/first-second-derivative-convolution-quadratic-fitting-and-all-that-via-MCMC/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Agenda"&gt;Agenda&lt;a class="anchor-link" href="#Agenda"&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;I will look at in this post:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First,  how we approach fitting a curve to a perfect quadratic function, using first order and second order derivatives of the function. &lt;/li&gt;
&lt;li&gt;Second, how one can do curve fitting in a quadratic function via Monte Carlo Markov Chain(MCMC) via Pymc.  &lt;/li&gt;
&lt;li&gt;Last, how convolution could be used for numerical differentiation to estimate the coefficients of quadratic function.&lt;/li&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Fri, 13 Jun 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-06-13:/work/notes/2014-06-13/first-second-derivative-convolution-quadratic-fitting-and-all-that-via-MCMC/</guid></item><item><title>2200 CS Faculty in 51 University Analysis</title><link>http://bugra.github.io/work/notes/2014-05-31/2200-cs-faculty-in-51-university-analysis/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Data is from &lt;a href="https://docs.google.com/spreadsheet/ccc?key=0AubxN1_iO2c-dElJVWFqaTFDeHBkRVFyUzJUWk9oRlE&amp;amp;usp=sharing#gid=0"&gt;here&lt;/a&gt; and explanation of how it is collected is &lt;a href="http://cs.brown.edu/people/alexpap/faculty_dataset.html"&gt;here&lt;/a&gt;. It was a classroom assignment to crowdsource the faculty information(when they join to the university, what is their rank and where they get doctorate and so on). The not-so good taxonomy for the fields that faculty are working is taken from &lt;a href="http://academic.research.microsoft.com/?SearchDomain=2"&gt;Microsoft Academic Search&lt;/a&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 31 May 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-05-31:/work/notes/2014-05-31/2200-cs-faculty-in-51-university-analysis/</guid></item><item><title>Simple Bayesian Network via Monte Carlo Markov Chain</title><link>http://bugra.github.io/work/notes/2014-05-23/simple-bayesian-network-via-monte-carlo-markov-chain-mcmc-pymc/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;After I put some material to the blog around Monte Carlo Markov Chain, I get some emails which ask how to do apply MCMC in Bayesian Networks. To keep DRY and KISS principles in mind, here is my attempt to explain the one of the most simple Bayesian Network via MCMC using PyMC, Sprinkler.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Fri, 23 May 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-05-23:/work/notes/2014-05-23/simple-bayesian-network-via-monte-carlo-markov-chain-mcmc-pymc/</guid></item><item><title>Entropy and Perplexity on Image and Text</title><link>http://bugra.github.io/work/notes/2014-05-16/entropy-perplexity-image-text/</link><description>
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Fri, 16 May 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-05-16:/work/notes/2014-05-16/entropy-perplexity-image-text/</guid></item><item><title>PyData Silicon Valley 2014</title><link>http://bugra.github.io/work/notes/2014-05-12/pydata-silicon-valley-2014/</link><description>&lt;p&gt;&lt;img alt="Pydata" src="http://i.imgur.com/tInmSM1.png" title="PyData"&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;After every Python-related event, I keep telling myself that other language people have &lt;strong&gt;no idea&lt;/strong&gt; what they are missing. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Yes, we have GIL(Global Interpreter Lock), yes unicode is painful especially if you are doing a lot text-related stuff, yes Python is slow, yes static typing may prevent most of …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Mon, 12 May 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-05-12:/work/notes/2014-05-12/pydata-silicon-valley-2014/</guid></item><item><title>Robust Regression and Outlier Detection via Gaussian Processes</title><link>http://bugra.github.io/work/notes/2014-05-11/robust-regression-and-outlier-detection-via-gaussian-processes/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Previously, I wrote &lt;a href="http://bugra.github.io/work/notes/2014-03-31/outlier-detection-in-time-series-signals-fft-median-filtering/"&gt;outlier detection using FFT and Median Filtering&lt;/a&gt; and &lt;a href="http://bugra.github.io/work/notes/2014-04-26/outlier-detection-markov-chain-monte-carlo-via-pymc/"&gt;outlier detection via MCMC&lt;/a&gt;. This post will be third in outlier detection series.&lt;/p&gt;
&lt;p&gt;In the last post, I showed after removal of the outliers, one can do a linear regression on the remaining data which is called &lt;strong&gt;robust linear regression&lt;/strong&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sun, 11 May 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-05-11:/work/notes/2014-05-11/robust-regression-and-outlier-detection-via-gaussian-processes/</guid></item><item><title>Outlier Detection via Markov Chain Monte Carlo</title><link>http://bugra.github.io/work/notes/2014-04-26/outlier-detection-markov-chain-monte-carlo-via-pymc/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Previously, I wrote &lt;a href="http://bugra.github.io/work/notes/2014-03-31/outlier-detection-in-time-series-signals-fft-median-filtering/"&gt;outlier detection using FFT and Median Filtering&lt;/a&gt; and this post will be second in that series where I will look at the outlier detection in time-series using Markov Chaing Monte Carlo(MCMC). If you are familiar with Python and want to use MCMC, you should definitely check out &lt;a href="https://pymcmc.readthedocs.org/en/latest/"&gt;PyMC&lt;/a&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 26 Apr 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-04-26:/work/notes/2014-04-26/outlier-detection-markov-chain-monte-carlo-via-pymc/</guid></item><item><title>Alternating Least Squares Method for Collaborative Filtering</title><link>http://bugra.github.io/work/notes/2014-04-19/alternating-least-squares-method-for-collaborative-filtering/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Recommender-Systems"&gt;Recommender Systems&lt;a class="anchor-link" href="#Recommender-Systems"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;&lt;h3 id="An-Informal-Definition"&gt;An Informal Definition&lt;a class="anchor-link" href="#An-Informal-Definition"&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Recommender systems is a family of methods that enable filtering through large observation and information space in order to provide recommendations in the information space that user does not have any observation, where the information space is all of the available items that user could choose or select and observation space is what user experienced or observed so far.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 19 Apr 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-04-19:/work/notes/2014-04-19/alternating-least-squares-method-for-collaborative-filtering/</guid></item><item><title>Workflow Engine Comparison(First Impressions)</title><link>http://bugra.github.io/work/notes/2014-04-13/workflow-engine-comparison-first-impressions/</link><description>&lt;p&gt;I was looking at different options for workflow engines. I have
some experience in Oozie, little experience in Luigi and no experience
in Azkaban. In this post, I will try to give an overview of these
engines in terms of their advantages and disadvantages. Take my word
with a grain …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sun, 13 Apr 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-04-13:/work/notes/2014-04-13/workflow-engine-comparison-first-impressions/</guid></item><item><title>Graphs, Databases and Graphlab</title><link>http://bugra.github.io/work/notes/2014-04-06/graphs-databases-and-graphlab/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;I will talk about graphs, graph databases and mainly the paper that powers &lt;a href="http://graphlab.com/"&gt;Graphlab&lt;/a&gt;. At the end of the post, I will go over briefly basic capabilities of Graphlab as well.&lt;/p&gt;
&lt;h2 id="Graph-Definition"&gt;Graph Definition&lt;a class="anchor-link" href="#Graph-Definition"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Generally speaking, graphs that are relevant to graph theory and graph databases are defined as following(most general definition):&lt;/p&gt;
&lt;p&gt;Graph is an ordered pair $G = (V, E)$ 
where the $V$ represents the vertices(nodes) of graph and $E$ represents the edges(relations) that connect the nodes. If edges do not have any orientations, then graph is composed of unordered pairs and graph is called undirected graph.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sun, 06 Apr 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-04-06:/work/notes/2014-04-06/graphs-databases-and-graphlab/</guid></item><item><title>Outlier Detection in Time-Series Signals using FFT and Median Filtering</title><link>http://bugra.github.io/work/notes/2014-03-31/outlier-detection-in-time-series-signals-fft-median-filtering/</link><description>
&lt;div class="cell border-box-sizing code_cell rendered"&gt;
&lt;div class="input"&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Mon, 31 Mar 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-03-31:/work/notes/2014-03-31/outlier-detection-in-time-series-signals-fft-median-filtering/</guid></item><item><title>8th NYAS Machine Learning Symposium 2014</title><link>http://bugra.github.io/work/notes/2014-03-28/nyas-machine-learning-symposium-2014/</link><description>&lt;p&gt;I attended to &lt;a href="http://www.nyas.org/Events/Detail.aspx?cid=2cc3521e-408a-460e-b159-e774734bcbea"&gt;NYAS 8th Machine Learning Symposium&lt;/a&gt; and here are the notes
that I took from the event. It may contain errors and mistakes. If you
find any, please let me  know.&lt;br&gt;
On personal view, it was worse than the previous machine learning
symposium(7th) in both posters and …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Fri, 28 Mar 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-03-28:/work/notes/2014-03-28/nyas-machine-learning-symposium-2014/</guid></item><item><title>Data Products Made Easy</title><link>http://bugra.github.io/work/notes/2014-03-21/data-products-made-easy/</link><description>&lt;p&gt;I read &lt;a href="http://www.oreilly.com/data/free/data-jujitsu.csp"&gt;Data Jujitsu&lt;/a&gt;
recently and enjoyed it a lot. DJ Patil presents a nice set of hard
learned things that he experienced in (mainly) Linkedin. I like this
type of &lt;strong&gt;real&lt;/strong&gt; experiences rather than a set of rules that advocates
a too ideal world and behave according to that …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Fri, 21 Mar 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-03-21:/work/notes/2014-03-21/data-products-made-easy/</guid></item><item><title>Short Notes on Thinking with Data</title><link>http://bugra.github.io/work/notes/2014-03-18/thinking-with-data-short-notes/</link><description>&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Arguments are how we convince ourselves that something is true.&lt;/li&gt;
&lt;li&gt;Argument theory provides a useful set of mental models for
  understanding arguments.&lt;/li&gt;
&lt;li&gt;Data work is held together by arguments.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Data are just (sadly) observations.&lt;/li&gt;
&lt;li&gt;What we want is knowledge and representation, maybe even understanding
  and insight.&lt;/li&gt;
&lt;li&gt;By doing …&lt;/li&gt;&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Tue, 18 Mar 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-03-18:/work/notes/2014-03-18/thinking-with-data-short-notes/</guid></item><item><title>Document Visualization with JS Divergence Matrix and Multi Dimensional Scaling</title><link>http://bugra.github.io/work/notes/2014-03-16/jensen-shannon-divergence-matrix-multi-dimensional-scaling/</link><description>&lt;h3&gt;Bag of Words (BoW)&lt;/h3&gt;
&lt;p&gt;In text search and classification of text, word order contributes 
less to the search result or document classification unless it is part of 
a phrase. Therefore, it is a common practice to use the frequency
of occurrence of words sacrificing the word order which is known …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sun, 16 Mar 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-03-16:/work/notes/2014-03-16/jensen-shannon-divergence-matrix-multi-dimensional-scaling/</guid></item><item><title>IMDB Top 100K Movies Analysis in Depth Part 4</title><link>http://bugra.github.io/work/notes/2014-03-09/imdb-top-100-movies-analysis-in-depth-part-4/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This post is fourth in the series. See the &lt;a href="/work/notes/2014-02-15/imdb-top-100K-movies-analysis-in-depth-part-1/"&gt;first&lt;/a&gt;, &lt;a href="/work/notes/2014-02-23/imdb-top-100-movies-analysis-in-depth-part-2/"&gt;second&lt;/a&gt; and &lt;a href="/work/notes/2014-03-01/imdb-top-100-movies-analysis-in-depth-part-3/"&gt;third&lt;/a&gt; one. I explained the data sources in the third post. In this post, I will look at age and height distribution of the actresses and actors over time, and revenue of the movies per category. This is the last post for this series, I promise.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sun, 09 Mar 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-03-09:/work/notes/2014-03-09/imdb-top-100-movies-analysis-in-depth-part-4/</guid></item><item><title>IMDB Top 100K Movies Analysis in Depth Part 3</title><link>http://bugra.github.io/work/notes/2014-03-01/imdb-top-100-movies-analysis-in-depth-part-3/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;This post is third in the series. See the &lt;a href="/work/notes/2014-02-15/imdb-top-100K-movies-analysis-in-depth-part-1/"&gt;first&lt;/a&gt; and &lt;a href="/work/notes/2014-02-23/imdb-top-100-movies-analysis-in-depth-part-2/"&gt;second&lt;/a&gt; one.&lt;/p&gt;
&lt;h2 id="Data"&gt;Data&lt;a class="anchor-link" href="#Data"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;IMDB does not provide box revenue for all of the movies so I pulled this information from different sources; freebase and wikipedia to name a few. Generally, the conflicts(movie name and movie year) is resolved by using the information IMDB provides as it is more reliable. If this information is not available or missing, I used wikipedia information to resolve the conflicts. For the box revenue, freebase provides only domestic gross revenue for the movie(strictly in USA) ,so it is not very useful as I wanted to observe worldwide gross revenue. For this, I depend on wikipedia, imdb, blogs and some other websites which periodically publishes worldwide gross revenue of movies. However, the data unlike previous weeks may occassionally contain incorrect values as the sources are scattered and not very reliable. That being said, it is generally hard to validate the box revenue information on a timely basis as movies may also generate money through different channels. I take max revenue values when such a conflict occurs. My hope is that the max revenue would be the most updated revenue for the selected movie. By combining different sources, I could only get 6672 movies' worldwide gross revenue. 95% movies in this list are in the most popularly voted 12000 movies in IMDB. Therefore, the distribution graphs of revenue are biased towards to the ones that have high number of votes in IMDB.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 01 Mar 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-03-01:/work/notes/2014-03-01/imdb-top-100-movies-analysis-in-depth-part-3/</guid></item><item><title>IMDB Top 100K Movies Analysis in Depth Part 2</title><link>http://bugra.github.io/work/notes/2014-02-23/imdb-top-100-movies-analysis-in-depth-part-2/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h3 id="Data"&gt;Data&lt;a class="anchor-link" href="#Data"&gt;&amp;#182;&lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Data is from IMDB and includes top 100042 popularly voted movies. This post is second in series, see the &lt;a href="/work/notes/2014-02-15/imdb-top-100K-movies-analysis-in-depth-part-1/"&gt;first post&lt;/a&gt;.  I had some great feedback from &lt;a href="https://news.ycombinator.com/item?id=7249717"&gt;HN&lt;/a&gt; and decided to deal with more on categories of movies.
In this one, I will first look at number of movies per category over time and rating of the categories. Second, I will compare popularly voted directors with other directors, give best directors for popularly voted categories. At the end, I will look at the correlation of the categories and do PCA on the movies. As in the first post, I will let the data speak for itself rather than explaining every single graph.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sun, 23 Feb 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-02-23:/work/notes/2014-02-23/imdb-top-100-movies-analysis-in-depth-part-2/</guid></item><item><title>IMDB Top 100K Movies Analysis in Depth Part 1</title><link>http://bugra.github.io/work/notes/2014-02-15/imdb-top-100K-movies-analysis-in-depth-part-1/</link><description>
&lt;div class="cell border-box-sizing text_cell rendered"&gt;
&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Data"&gt;Data&lt;a class="anchor-link" href="#Data"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Data is from IMDB and it includes all of the popularly voted 100042 movies from 1950 to 2013.(I know why 100000 is there but have no idea how 42 movies get squeezed. Instead of blaming my web scraping skills, I blame the &lt;a href="https://www.google.com/search?q=the+answer+to+life+the+universe+and+everything"&gt;universe&lt;/a&gt;, though).&lt;/p&gt;
&lt;p&gt;The reason why I chose the number of
votes as a metric to order the movies is because, generally the information (title, certificate, outline, director and so on) about movie are more likely to be complete for the movies that have high number of votes. Moreover, IMDB uses number of votes as a metric to determine the ranking as well so number of votes also correlate with the rating as well.  Further, everybody at least has an idea on IMDB Top 250 or IMDB Top 1000 which are ordered by the ratings computed by IMDB.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 15 Feb 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-02-15:/work/notes/2014-02-15/imdb-top-100K-movies-analysis-in-depth-part-1/</guid></item><item><title>Pig Not So Foreign Language Paper Notes</title><link>http://bugra.github.io/work/notes/2014-02-09/pig-not-so-foreign-language-paper-notes/</link><description>&lt;p&gt;These are notes that I took from the &lt;a href="http://infolab.stanford.edu/~usriv/papers/pig-latin.pdf"&gt;paper&lt;/a&gt;, where the authors
explain the design principles and some theoretical aspects of Pig the
programming language. I gave a basic overview in &lt;a href="/work/notes/2014-02-08/pig-advantages-and-disadvantages/"&gt;Pig Advantages and
Disadvantages&lt;/a&gt;. &lt;/p&gt;
&lt;h2&gt;Before Pig&lt;/h2&gt;
&lt;p&gt;Before Pig and Hadoop, there was mighty Map-Reduce paradigm for
parallellization and data …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sun, 09 Feb 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-02-09:/work/notes/2014-02-09/pig-not-so-foreign-language-paper-notes/</guid></item><item><title>Pig Advantages and Disadvantages</title><link>http://bugra.github.io/work/notes/2014-02-08/pig-advantages-and-disadvantages/</link><description>&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Apache Pig is a dataflow language that is built on top of Hadoop to make
it easier to process, clean and analyze "big data" without having to write
vanilla map-reduce jobs in Hadoop.&lt;br&gt;
It has also a lot of relational database features. Good old &lt;code&gt;join&lt;/code&gt;s, &lt;code&gt;distinct&lt;/code&gt;, &lt;code&gt;union&lt;/code&gt; and …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 08 Feb 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-02-08:/work/notes/2014-02-08/pig-advantages-and-disadvantages/</guid></item><item><title>Cultural Data Project Part 2</title><link>http://bugra.github.io/work/notes/2014-02-04/cultural-data-project-part-2/</link><description>&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;&lt;a href="/work/notes/2014-02-01/cultural-data-project-part-1/"&gt;First Part&lt;/a&gt; shows some basic statistics on &lt;a href="http://www.culturaldata.org/"&gt;Cultural Data Project&lt;/a&gt;. In order to get a better insight how do these companies make their money and different ways to monetize their services, I looked at the correlation of their revenue with other metrics. This could be quite important if the …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Tue, 04 Feb 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-02-04:/work/notes/2014-02-04/cultural-data-project-part-2/</guid></item><item><title>Cultural Data Project Part 1</title><link>http://bugra.github.io/work/notes/2014-02-01/cultural-data-project-part-1/</link><description>&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Data is from &lt;a href="http://www.culturaldata.org/"&gt;Cultural Data Project&lt;/a&gt;. In order to get a better
understanding, I seggregated the data by organization type. There are
total 48 different organization types. Data follows &lt;a href="http://www.culturaldata.org/wp-content/themes/cdp/pdf/CDP-BlankProfile.pdf"&gt;data profile&lt;/a&gt; structure
and I grouped organizations into 6 different subsections;
employment statistics, their activities, pricing, website activity,
attendance and …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 01 Feb 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-02-01:/work/notes/2014-02-01/cultural-data-project-part-1/</guid></item><item><title>Unreasonable Effectiveness of Metadata</title><link>http://bugra.github.io/work/notes/2014-01-30/unreasonable-effectiveness-of-metadata/</link><description>&lt;h2&gt;Metadata&lt;/h2&gt;
&lt;p&gt;Metadata could be translated as data about data if we want to translate
'mot à mot'. Generally, it defines what the data is about 
and gives some descriptive information around that. Still quite 
abstract huh? If the content of email is data, then sender,
receiver, date and time could …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Thu, 30 Jan 2014 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2014-01-30:/work/notes/2014-01-30/unreasonable-effectiveness-of-metadata/</guid></item><item><title>PCA, EigenFace and All That</title><link>http://bugra.github.io/work/notes/2013-07-27/PCA-EigenFace-And-All-That/</link><description>&lt;p&gt;PCA(Principal Component Analysis) is one of the most commonly used unsupervised learning algorithm to compress, extract features for data and even for dimensionality reduction purposes. It has quite a lof of applications as follows: &lt;/p&gt;
&lt;h3&gt;Applications&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Useful for compression and classfication of data.&lt;/li&gt;
&lt;li&gt;Aim is to reduce the number of …&lt;/li&gt;&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 27 Jul 2013 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2013-07-27:/work/notes/2013-07-27/PCA-EigenFace-And-All-That/</guid></item><item><title>Spectral Leakage</title><link>http://bugra.github.io/work/notes/2012-09-15/Spectral-Leakage/</link><description>&lt;p&gt;Have you ever analyzed(take FFT) a signal which has one or two main frequency components and found out that there are many more components than you expect even if there is no noise in the signal?  One of the reasons why it has more frequency components is spectral leakage …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 15 Sep 2012 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2012-09-15:/work/notes/2012-09-15/Spectral-Leakage/</guid></item><item><title>Phase Detection in Digital Signals</title><link>http://bugra.github.io/work/notes/2012-09-01/Phase-Detection/</link><description>&lt;p&gt;Phase Detection is an important concept in radar signals. It could be used to determine the time delay between radar signals and this time delay could be used to infer the distance of the object from the radar, which is the main aim of the radar. Even if it is …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 01 Sep 2012 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2012-09-01:/work/notes/2012-09-01/Phase-Detection/</guid></item><item><title>MongoDB Notes</title><link>http://bugra.github.io/work/notes/2012-06-16/MongoDB-Notes/</link><description>&lt;p&gt;Some Properties:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MongoDB instances act as high-level container.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Collection&lt;/em&gt; is a synonym of table in sql.&lt;/li&gt;
&lt;li&gt;Collections are made by &lt;em&gt;documents&lt;/em&gt;. (document =&amp;gt; row)&lt;/li&gt;
&lt;li&gt;Document is made by &lt;em&gt;fields&lt;/em&gt;. (field =&amp;gt; column)&lt;/li&gt;
&lt;li&gt;Indices are similar to sql databases.&lt;/li&gt;
&lt;li&gt;Cursor can count or skip ahead without actually pulling down data.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;A collection does …&lt;/p&gt;&lt;/blockquote&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Bugra Akyildiz</dc:creator><pubDate>Sat, 16 Jun 2012 00:00:00 +0000</pubDate><guid isPermaLink="false">tag:bugra.github.io,2012-06-16:/work/notes/2012-06-16/MongoDB-Notes/</guid></item></channel></rss>